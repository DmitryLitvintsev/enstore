<html> <head>

<title> D0EnSrv1 </title>

</head>

<body BGCOLOR=#FFFFFF>

<font size=7><b><i>
<center> D0EnSrv1</center>
</i></b></font>
<br><p>

<br><p>
<center>$Revision$</center>
<center>$Date$GMT</center>
<br><p>

<br><p>

D0EnSrv1 is the node that contains all information that needs to be
backed up and preserved.  That is, it has the Enstore file and volume
databases, and the pnfs databases.

<p>
<p>
File Clerk
<ul>

<li>
<p>
<li>
<p>
<li>
</ul>

<br>
<br>
<br>
Volume Clerk
<ul>

<li>
<p>
<li>
<p>
<li>
</ul>


<br>
<br>
<br>
PNFS
<ul>

<li> <a href="http://watphrakeo.desy.de/pnfs">PNFS:</a> Perfectly
Normal File System, written and maintained by DESY, provides the
namespace for the files that D0 transfers in and out of the robot.

<p>
<li> <a href="http://www-hppc.fnal.gov/enstore/design.html#pnfs">
Detailed Information </a> on how Enstore uses DESY's PNFS is available
from the <a href="http://www-hppc.fnal.gov/enstore/design.html">
Enstore Technical Document.</a> Installation procedures and command
details are covered here.

<p>
<li> The root of the PNFS directory tree is /diska/pnfs. This
directory is on a raid level-1 (software mirroring) disk.
  <ul>

     <li> A backup is made once an hour and copied to d0ensrv3

     <li> Rsync is run once every 5 minutes and a complete copy of the
     directory tree is made to a 2nd (independent) raid disk on
     d0ensrv1.

  </ul>

<p>
<li> Two files must be in /usr/etc, pnfsObserver and pnfsSetup, for
the automated pnfs scripts to work.

<p>
<li> You can gain access to the PNFS admin commands by logging into
d0ensrv1 and typing "setup pnfs", and "mount /pnfs/fs".

  <br> Typical commands are:
     <ul>

        <li> Stopping manually: pnfs.server stop

        <li> Starting manually: pnfs.server start

        <li> Checking export list: pmount show host &lt nodename &gt

        <li> Adding a host, and <b>ONLY AFTER PERMISSION FROM LEE
        LUEKING </b> or his superiors, pmount add &lt nodename &gt &lt
        mountpoint &gt
      </ul>

<p>
<li> A remote node needs an entry in their fstab similar to
"d0ensrv1:/sam-ait /pnfs/sam/ait nfs user,intr,bg,hard,rw,noac 0 0",
in order to be able to mount pnfs.

<p>
<li> It is also possible for nodes to automount pnfs.  We do not
provide any support to help people with their automount problems
whatsoever.

<p>
<li> The PNFS wormhole is in /pnfs/fs/admin/etc/config/flags/

<p>
<li> The PNFS exports list is in /pnfs/fs/admin/etc/exports/

<p>
<li> The PNFS user tree starts at /pnfs/fs/usr/.

<p> <li> PNFS metadata information can be examined by logging into
d0ensrv1 and typing "setup enstore" and then "pnfs cat filename 4"

<p>
<li> Sometimes if there is a crash and the raid disks are not shut
down properly, it takes an extended time to fix them on the next
reboot.  If this happens, PNFS may not start correctly and may have to
be stopped and restarted. Sometimes it is better to reboot and start
again after the disk fixes have been resolved.


</ul>

<br>
<br>
<br>
Cron jobs executing on d0ensrv1:
<ul>

<li> user root - plog.  If this fails, either you are out of disk
space on /diska for the pnfs logs or else something is not configured
correctly. (This cronjob runs in the pnfs framework, not the enstore
one).

<li> user root - pnfsFastBackup. If this fails either you are out of
disk space on /diska for the backups, or the backup node, d0ensrv3, is
down or out of disk space, or the network connection to the backup
node is down. (This cronjob runs in the pnfs framework, not the
enstore one).

<li> user root - delfile. If this fails, there is probably with the
file clerk.

<li> user root - rsync. If this fails, there are problems with the
raid disks, /diska or /diskb.

<li> user enstore backup.  If this fails either you are out of disk
space on /diskb for the backups, or the backup node, d0ensrv3, is down
or out of disk space, or the network connection to the backup node is
down.

<li> user enstore - checkfile. This doesn't work right now.

<li> user enstore - checkvolume. This doesn't work right now.

<li> user root - tarit. If this fails, the most likely reason is
because either rip8 (the backup node for the ide system disk) or the
network connection to rip8 is down.

</ul>



<br>
<br>
<br>
Raid Software
<ul>

<li> Mirroring has been disabled in the standard linux kernel.  To
re-enable it, a patch from
ftp://ftp.kernel.org/pub/linux/daemons/raid/alpha/raid0145-19990824-2.2.11.patch
was applied to the 2.2.13 linux kernel.  This went smoothly.

<li> Up to date raid tools, not available via the standard
distribution, also had to be installed to make mirroring work
properly. These raidtools were gotten from the same place as the raid
patch,
ftp://ftp.kernel.org/pub/linux/daemons/raid/alpha/raidtools-19990824-0.90.tar.gz

<li> The raid devices are declared in /etc/raidtab (not the older
/etc/mdtab). There are 2 raid disks on d0ensrv1 and each one is
composed of 2 9 GB scsi disks to form 1 9 GB scsi disk.  There are no
spare disks in the configuration.

<li> You can check the <a
href="http://d0ensrv2/enstore/d0ensrv1_raid_status.txt"> Raid Status
Page </a> to look for errors.  This page is updated every few
minutes. You can also log into d0ensrv1 and type "raidinfo" to get
current values.  One needs to pay particular attention to the 1st few
lines that show the disk's current state.

</ul>



<br>
<br>
<br>
Bootup
<ul>

<li> Raidstart is invoked.

<li> Each raid disk has e2fsck run on it to correct any errors

<li> The pnfs servers are started.

<li> The Enstore servers are started.

<li> FTT makes /dev/rmt scsi devices.

<li> The BMC watchdog is armed and deadman is started at real-time
priority.


</ul>

<br>
<br>
<br>
Some Details:
<ul>

<li> Each serial line is configured at 19200 baud rate.

<li> The linux kernel, via lilo, has been configured to send its root
console output to ttyS0. The kernel sends its output to ttyS0 by
adding "append="console=ttyS0,19200 console=tty0 ..." to the kernel
stanza.

<li> The barracuda 9 GB hard drives needs to have several options
enabled to operate efficiently.  Do this by adding a line to each
stanza of lilo.conf: append=".... console=tty0
ncr53c8xx=tags:4,sync:10,ultra:y"

<li> The bios needs to be configured to use vt100 terminals, xon/xoff
flow control, and ???.  Also lilo needs to have the following line
once, ahead of all stanzas, "serial=0,19200n8".

<li> Gettys need to be running on in order to open a tty session. The
/etc/inittab has to have "c:12345:respawn:/sbin/mingetty ttyS0" line.

<li> A backup of the system ide disk is made once per day to
rip8:/fnal/enstore/servers/srv1.  This allows one to have an
up-to-date copy in order to replace a failed node. Procedures (tarit
and loadit in /root) are in place to do this; One also needs the
d0enrtbt floppy to create a replacement system disk.

<li> Although a system disk backup is made daily, the user's home
directory files are not copied. No one should be saving files on these
nodes without copies in appropriately backed up machines.

</ul>

</body></html>
