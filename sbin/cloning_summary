#! /bin/sh

# $Id$

#Make tables showing the progress of cloning (or squeezing) tapes.

#Make sure to set a timeout.
timeout='--timeout 10 --retries 3'

#First obtain the directory to write the output.
html_dir=`enstore conf $timeout --show crons html_dir`
if [ ! -d "$html_dir" ]; then
    echo HTML directory $html_dir not found.
    exit 1
fi
#If the inventory directory does not exist, create it.
inventory_dir=$html_dir/tape_inventory
if [ ! -d "$inventory_dir" ]; then
    mkdir -p $inventory_dir
fi
#If the inventory directory does not exist, create it.
plots_dir=$html_dir/migration_summary
plots_link=$plots_dir/plot_enstore_system.html

#Second obtain the directory to put a link to.
url_dir=`enstore conf $timeout --show crons url_dir`

#Obtain the db port number.
DB_PORT=`enstore conf $timeout --show database dbport`
if [ -z "$DB_PORT" ]; then
    echo "dbport not found in configuration."
    exit 1
fi

#Obtain the db name.
DB_NAME=`enstore conf $timeout --show database dbname`
if [ -z "$DB_NAME" ]; then
    echo "dbname not found in configuration."
    exit 1
fi

#Obtain the db host.
DB_HOST=`enstore conf $timeout --show database dbhost`
if [ -z "$DB_HOST" ]; then
    echo "dbhost not found in configuration."
    exit 1
fi

#Obtain the db user/role.
DB_USER=`enstore conf $timeout --show database dbuser`   #dbuser_reader?
if [ -z "$DB_USER" ]; then
    echo "dbuser not found in configuration."
    exit 1
fi

#Get the temporary directory to use.
temp_dir=`enstore conf $timeout --show crons tmp_dir`
if [ ! -d "$temp_dir" ]; then
    temp_dir=/tmp
fi

#Create the variables that point to the files to output to.
fname=CLONING_SUMMARY
output_file=$inventory_dir/$fname
temp_file=$temp_dir/$fname.temp

#If we write to a temp file, and swap in it when we are done, there will
# not any time when the page is empty becuase the scipt is still writing
# the file.
rm -f $temp_file

#Make sure we know how up-to-date this is.
echo -e Clongin Report: `date` > $temp_file 2>&1
echo -e Brought to You by: `basename $0` "\n" >> $temp_file 2>&1


echo                   >> $temp_file 2>&1
echo "===============" >> $temp_file 2>&1
echo "Cloning per Day" >> $temp_file 2>&1
echo "===============" >> $temp_file 2>&1
echo                   >> $temp_file 2>&1

echo "Creating Cloning per Day" `date`

# Note: This sql command is similar to the daily plots and daily Duplicated
# table in the src/migration_summary_plotter_module.py and
# sbin/duplication_summary scripts, respectively.  Be sure to modify them
# when you modify this sql statement.
psql -p $DB_PORT -h $DB_HOST -U $DB_USER $DB_NAME -c "
/*This outer select just sorts the merged s1, s2 and s3 'day' columns into
  a unified sorted order. */
select * from
(
/* This inner select combines three sub selects sorted by day and
   media type. */
select CASE WHEN s1.day is not null THEN s1.day
            WHEN s2.day is not null THEN s2.day
            WHEN s3.day is not null THEN s3.day
            ELSE NULL
       END as day,
       CASE WHEN s1.media_type is not null THEN s1.media_type
            WHEN s2.media_type is not null THEN s2.media_type
            WHEN S3.media_type is not null THEN s3.media_type
            ELSE NULL
       END as media_type,
       /*CASE WHEN s2.started is not NULL THEN s2.started
            ELSE 0
       END as started,*/
       CASE WHEN s1.completed is not NULL THEN s1.completed
            ELSE 0
       END as completed,
       CASE WHEN s3.closed is not NULL THEN s3.closed
            ELSE 0
       END as closed
from

/*Three sub selects get the count for each day and media for number of
  volumes started, migrated/duplicated and closed. */

/****  s1  ****/
(
select date(time) as day,
       /* It should be as simple as just using the media_type. However,
          LTO1 and LTO2 at FNAL are both set as 3480 do to limitations
          in the AML/2 when it was first put into use. */
       /*media_type,*/
       CASE WHEN media_type = '3480' and capacity_bytes = '107374182400'
            THEN 'LTO1'
            WHEN media_type = '3480' and capacity_bytes = '214748364800'
            THEN 'LTO2'
            WHEN media_type = '3480' and capacity_bytes < 100
            THEN NULL    --Cleaning tape; skip it.
            ELSE media_type
       END as media_type,
       count(distinct CASE WHEN system_inhibit_1 in ('cloned')
                            THEN label
                            ELSE NULL
                      END) as completed

from volume,migration_history
where volume.id = migration_history.src_vol_id
      and volume.library not like '%shelf%'
      and volume.media_type != 'null'
      and volume.system_inhibit_1 in ('cloned')
      /* This time sub-query is needed to limit test volumes migrated
         multiple times to be counted only once. */
      and time = (select max(time)
                  from migration_history m2
                  where m2.src_vol_id = volume.id)
      and capacity_bytes > 500  --Skip cleaning tapes.
group by day,media_type,capacity_bytes
order by day,media_type
) as s1
/****  s1  ****/

/****  s2  ****/
full join (
select date(state.time) as day,
       /* It should be as simple as just using the media_type. However,
          LTO1 and LTO2 at FNAL are both set as 3480 do to limitations
          in the AML/2 when it was first put into use. */
       /*media_type,*/
       CASE WHEN media_type = '3480' and capacity_bytes = '107374182400'
            THEN 'LTO1'
            WHEN media_type = '3480' and capacity_bytes = '214748364800'
            THEN 'LTO2'
            WHEN media_type = '3480' and capacity_bytes < 100
            THEN NULL    --Cleaning tape; skip it.
            ELSE media_type
       END as media_type,
       count(distinct volume.label) as started
from volume,migration_history,state
where volume.id = migration_history.src_vol_id
      and volume.id = state.volume
      and volume.library not like '%shelf%'
      and volume.media_type != 'null'
      and volume.system_inhibit_1 in ('cloning', 'cloned')
      /* Hopefully, setting state.time like this will correctly handle
         all vintages of the migration process.  The migrating and duplicating
         stages were added September of 2008. */
      and state.time = (select min(s5.time) from (
                        select CASE WHEN s2.value in ('cloning')
                                    THEN min(s2.time)
                                    WHEN s2.value in ('readonly')
                                         and time > current_timestamp - interval '30 days'
                                    THEN min(s2.time)
                                    WHEN s2.value in ('cloned')
                                    THEN min(s2.time)
                                    ELSE NULL
                               END as time
                        from state s2
                        where s2.volume = volume.id
                              and s2.value in ('cloning', 'cloned',
                                               'readonly')
                        group by s2.value, time
                        order by s2.value, time
                        ) as s5)
      and capacity_bytes > 500  --Skip cleaning tapes.
group by day, volume.media_type,capacity_bytes
order by day, volume.media_type
) as s2 on (s1.day, s1.media_type) = (s2.day, s2.media_type)
/****  s2  ****/

/****  s3  ****/
full join (
select date(closed_time) as day,
       /* It should be as simple as just using the media_type. However,
          LTO1 and LTO2 at FNAL are both set as 3480 do to limitations
          in the AML/2 when it was first put into use. */
       /*media_type,*/
       CASE WHEN media_type = '3480' and capacity_bytes = '107374182400'
            THEN 'LTO1'
            WHEN media_type = '3480' and capacity_bytes = '214748364800'
            THEN 'LTO2'
            WHEN media_type = '3480' and capacity_bytes < 100
            THEN NULL    --Cleaning tape; skip it.
            ELSE media_type
       END as media_type,
       count(distinct label) as closed
from volume,migration_history
where volume.id = migration_history.src_vol_id
      and volume.library not like '%shelf%'
      and volume.media_type != 'null'
      and volume.system_inhibit_1 in ('cloned')
      /* This time sub-query is needed to limit test volumes migrated
         multiple times to be counted only once. */
      and closed_time = (select max(closed_time)
                         from migration_history m2
                         where m2.src_vol_id = volume.id)
      and capacity_bytes > 500  --Skip cleaning tapes.
group by day,media_type,capacity_bytes
order by day,media_type
) as s3 on (s2.day, s2.media_type) = (s3.day, s3.media_type)
/****  s3  ****/

group by s1.day,s2.day,s3.day,s1.media_type,s1.completed,s2.media_type,s2.started,s3.media_type,s3.closed
order by s1.day,s2.day,s3.day
) as inner_result order by day;
" >> $temp_file 2>&1

echo                     >> $temp_file 2>&1
echo "=================" >> $temp_file 2>&1
echo "Migration History" >> $temp_file 2>&1
echo "=================" >> $temp_file 2>&1
echo                     >> $temp_file 2>&1

echo "Creating Migration History" `date`

psql -p $DB_PORT -h $DB_HOST -U $DB_USER $DB_NAME -c " \
select migration_history.src as src_volume,
       /* It should be as simple as just using the media_type. However,
          LTO1 and LTO2 at FNAL are both set as 3480 do to limitations
          in the AML/2 when it was first put into use. */
       /*volume.media_type,*/
       CASE WHEN volume.media_type = '3480' and volume.capacity_bytes = '107374182400'
            THEN 'LTO1'
            WHEN volume.media_type = '3480' and volume.capacity_bytes = '214748364800'
            THEN 'LTO2'
            WHEN volume.media_type = '3480' and volume.capacity_bytes < 100
            THEN NULL    --Cleaning tape; skip it.
            ELSE volume.media_type
       END as src_type,
       migration_history.dst as dst_volume,
       /* It should be as simple as just using the media_type. However,
          LTO1 and LTO2 at FNAL are both set as 3480 do to limitations
          in the AML/2 when it was first put into use. */
       /*v2.media_type,*/
       CASE WHEN v2.media_type = '3480' and v2.capacity_bytes = '107374182400'
            THEN 'LTO1'
            WHEN v2.media_type = '3480' and v2.capacity_bytes = '214748364800'
            THEN 'LTO2'
            WHEN v2.media_type = '3480' and v2.capacity_bytes < 100
            THEN NULL    --Cleaning tape; skip it.
            ELSE v2.media_type
       END as dst_type,
       volume.system_inhibit_1 as migration,
       time as time_completed
from migration_history
left join volume on volume.id = migration_history.src_vol_id
left join volume as v2 on v2.id = migration_history.dst_vol_id
where volume.system_inhibit_1 = 'cloned'
order by time;
" >> $temp_file 2>&1

mv "$temp_file" "$output_file" #Do the temp file swap.

#For backward compatiblity make an html file too.
echo Starting to making html file for cloning.
rm -f $output_file.html
cat << EOF >> $output_file.html
<html> <head> <title>$tl_name Cloning Summary Page</title> </head>
<body>
<body bgcolor="#ffffff" text=#a0a0ff">
<meta http-equiv="Refresh" content="900">
<hr>
<pre>
EOF

    #We need to add a link to the web page with the plots on it.
    link="<a href=$url_dir/migration_summary/plot_enstore_system.html>Cloning Summary Plots</a>"

    #The following sed is used more like cat to append $output_file
    # to $output_file.html.  The fancy sed part just inserts the link
    # on line 3 in the process of "cat"ing the file.
    sed "3s;\(.*\);${link}\n\1;" $output_file >> $output_file.html

    echo >> $output_file.html
    echo ${link} >> $output_file.html
    echo >> $output_file.html

    cat << EOF >> $output_file.html
</pre>
<hr>
<hr>
</body>
EOF
