#! /bin/sh

# $Id$

#Dump the progress made in duplicating failed multiple copies and
# retro-actively making multiple copies.

#Make sure to set a timeout.
timeout='--timeout 10 --retries 3'

#First obtain the directory to write the output.
html_dir=`enstore conf $timeout --show crons html_dir`
if [ ! -d "$html_dir" ]; then
    echo HTML directory $html_dir not found.
    exit 1
fi
#If the inventory directory does not exist, create it.
inventory_dir=$html_dir/tape_inventory
if [ ! -d "$inventory_dir" ]; then
    mkdir -p $inventory_dir
fi
#If the inventory directory does not exist, create it.
plots_dir=$html_dir/migration_summary
plots_link=$plots_dir/plot_enstore_system.html

#Second obtain the directory to put a link to.
url_dir=`enstore conf $timeout --show crons url_dir`

#Obtain the db port number.
DB_PORT=`enstore conf $timeout --show database dbport`
if [ -z "$DB_PORT" ]; then
    echo "dbport not found in configuration."
    exit 1
fi

#Obtain the db name.
DB_NAME=`enstore conf $timeout --show database dbname`
if [ -z "$DB_NAME" ]; then
    echo "dbname not found in configuration."
    exit 1
fi

#Obtain the db host.
DB_HOST=`enstore conf $timeout --show database dbhost`
if [ -z "$DB_HOST" ]; then
    echo "dbhost not found in configuration."
    exit 1
fi

#Obtain the db user/role.
DB_USER=`enstore conf $timeout --show database dbuser`   #dbuser_reader?
if [ -z "$DB_USER" ]; then
    echo "dbuser not found in configuration."
    exit 1
fi

#Get the temporary directory to use.
temp_dir=`enstore conf $timeout --show crons tmp_dir`
if [ ! -d "$temp_dir" ]; then
    temp_dir=/tmp
fi

#Create the variables that point to the files to output to.
fname=MULTIPLE_COPY_SUMMARY
output_file=$inventory_dir/$fname
temp_file=$temp_dir/$fname.temp

#If we write to a temp file, and swap in it when we are done, there will
# not any time when the page is empty becuase the scipt is still writing
# the file.
rm -f $temp_file

#Make sure we know how up-to-date this is.
echo -e Multiple Copy Report: `date` > $temp_file 2>&1
echo -e Brought to You by: `basename $0` "\n" >> $temp_file 2>&1

echo                                    >> $temp_file 2>&1
echo "================================" >> $temp_file 2>&1
echo "Failed Multiple Copies Remaining" >> $temp_file 2>&1
echo "================================" >> $temp_file 2>&1
echo                                    >> $temp_file 2>&1

echo "Creating Failed Multiple Copies" `date`

psql -p $DB_PORT -h $DB_HOST -U $DB_USER $DB_NAME -c '
select active_file_copying.bfid,
       remaining as "copies remaining",
       active_file_copying.time as "waiting since"
from active_file_copying
left join file_copies_map on active_file_copying.bfid = file_copies_map.bfid
where remaining > 0 or alt_bfid is null
order by time;
' >> $temp_file 2>&1

echo                                                         >> $temp_file 2>&1
echo "=====================================================" >> $temp_file 2>&1
echo "Failed Multiple Copies Written Retro-actively per Day" >> $temp_file 2>&1
echo "=====================================================" >> $temp_file 2>&1
echo                                                         >> $temp_file 2>&1

echo "Creating Failed Multiple Copies Written Retro-actively per Day" 'data'

#This pulls the timestamp right out of the bfid.
psql -p $DB_PORT -h $DB_HOST -U $DB_USER $DB_NAME -c "
select date(TIMESTAMP 'epoch' + cast(substring(file_copies_map.alt_bfid from '([0-9]*).{5}$') as int) * interval '1 second') as day,
       count(file_copies_map.alt_bfid) as multiple_copies
from file_copies_map,active_file_copying
where file_copies_map.bfid = active_file_copying.bfid
group by day
order by day
;
" >> $temp_file 2>&1

echo                                  >> $temp_file 2>&1
echo "==============================" >> $temp_file 2>&1
echo "Failed Multiple Copies per Day" >> $temp_file 2>&1
echo "==============================" >> $temp_file 2>&1
echo                                  >> $temp_file 2>&1

echo "Creating Failed Multiple Copies" `date`

psql -p $DB_PORT -h $DB_HOST -U $DB_USER $DB_NAME -c "
select date(time) as day,
       count(bfid) as mulitple_copies_failed
from active_file_copying
where remaining > 0
group by day
having date(time) < date(current_timestamp - interval '72 hours')
order by day
;
" >> $temp_file 2>&1

echo                                     >> $temp_file 2>&1
echo "=================================" >> $temp_file 2>&1
echo "Multiple Copy File Family Summary" >> $temp_file 2>&1
echo "=================================" >> $temp_file 2>&1
echo                                     >> $temp_file 2>&1

echo "Creating Multiple Copy Summary" `date`

psql -p $DB_PORT -h $DB_HOST -U $DB_USER $DB_NAME -c "
select /* It should be as simple as just using the media_type. However,
          LTO1 and LTO2 at FNAL are both set as 3480 do to limitations
          in the AML/2 when it was first put into use. */
       /*media_type,*/
       CASE WHEN media_type = '3480' and capacity_bytes = '107374182400'
            THEN 'LTO1'
            WHEN media_type = '3480' and capacity_bytes = '214748364800'
            THEN 'LTO2'
            WHEN media_type = '3480' and capacity_bytes < 100
            THEN NULL    --Cleaning tape; skip it.
            ELSE media_type
       END as media_type,
       storage_group,
       file_family,
       count(file.bfid) as original_files,
       count(file_copies_map.alt_bfid) as duplicate_files,
       count(file.bfid) - count(file_copies_map.alt_bfid) as non_duplicated_files
from file
left join file_copies_map on file_copies_map.bfid = file.bfid
left join volume on file.volume = volume.id
where volume.file_family not like '%/_copy/__' escape '/'
group by media_type,storage_group,file_family,capacity_bytes
order by media_type,storage_group,file_family;
" >> $temp_file 2>&1

mv "$temp_file" "$output_file" #Do the temp file swap.

#For backward compatiblity make an html file too.
echo Starting to making html file for multiple copies.
rm -f $output_file.html
cat << EOF >> $output_file.html
<html> <head> <title>$tl_name Multiple Copies Summary Page</title> </head>
<body>
<body bgcolor="#ffffff" text=#a0a0ff">
<meta http-equiv="Refresh" content="900">
<hr>
<pre>
EOF

    #We need to add a link to the web page with the plots on it.
    link="<a href=$url_dir/migration_summary/plot_enstore_system.html>Migration Summary Plots</a>"

    #The following sed is used more like cat to append $output_file
    # to $output_file.html.  The fancy sed part just inserts the link
    # on line 3 in the process of "cat"ing the file.
    sed "3s;\(.*\);${link}\n\1;" $output_file >> $output_file.html

    echo >> $output_file.html
    echo ${link} >> $output_file.html
    echo >> $output_file.html

    cat << EOF >> $output_file.html
</pre>
<hr>
<hr>
</body>
EOF
