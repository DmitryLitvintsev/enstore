PRODUCT DESCRIPTION
====================

Enstore is a multi-Petabyte scale tape based Mass Storage System (MSS) for High
 Energy Physics (HEP) Experiments and other scientific endeavors. It has been 
designed to permit us to scale to multiple petabytes of storage capacity, manage
tens of terabytes per day in data transfers, support hundreds of users, and 
maintain data integrity. Enstore can be used for data storage needs of any 
scale, for different kinds of enterprises. The Enstore architecture allows easy
addition and replacement of hardware and software components. Enstore has the 
following major components:
SERVERS:
-------
 - Configuration server - maintain system configuration information and 
   present it to the rest of the system components.
 - Volume clerk - maintain volume part of the enstore database.
 - File clerk - maintain file part of the enstore database.
 - Info Server - provides read only functionality of File and Volume Clerks
 - Multiple, distributed library managers - provide queuing, optimization and 
   distribution of user requests to assigned movers.
 - Multiple, distributed movers - transfer data between user computers and 
   storage devices (tape drive, disk).
 - Multiple, distributed media changers - mount/dismount requested media in 
   the tape devices.
 - Log server - log messages from the Enstore components.
 - Alarm Server - generate alarms upon requests    from Enstore components.
 - Accounting Server - provides accounting of data transfers. Uses accounting 
   database to store accounting information.
 - Drivestat server - records tapedrives usage statistics into drivestat 
   database.
 - Event relay - relays events between enstore components.
   Example of one major event is the configuration change.
   The event subscribers will receive this event and reload their
   parameters from new configuration.
 - Inquisitor monitors enstore work and presents information 
   (in particular on web pages)
 - Ratekeeper collects information about data transfer rates

NAMESPACE - implemented by the PNFS package from DESY.
---------
ENCP - a client program used to copy files to and from tape libraries.
----
MONITORING system and administration tools
----------

The description of the system and other related information can be found the 
doc subdirecroty of enstore product. If you are new to enstore please read 
this document to start with.

LICENSING
=========
Enstore:
Terms are similar to those of the "Fermitools" license found at 
http://fermitools.fnal.gov/about/terms.html. That license is is roughly 
described as "BSD-like."

PNFS:
Enstore uses a PNFS virtual file system package that implements the Enstore 
namespace. It was written at DESY. The licensing information and code can 
be obtained at the dcache site (dcache.org). Installation instructions can 
be found 
here: http://www-pnfs.desy.de/gettingStarted.html
PNFS must be installed only on the node that will run pnfs server. PNFS 
mountpoint(s) must be exported to any node transferring data to or from 
enstore. Some instructions can be found here: 
http://ensrv1.fnal.gov/ISA/pnfs.html

HARDWARE REQUIREMENTS
=====================
HOSTS
------
There are no strict requirements for hosts. The general requirements are:
1. Dual CPU Intel processor (3.0GHZ or better),
2. 2GB (or more, better 8GB) of RAM
3. 120MB (or more) system disk
4. 1Gb (or more) network adapter for data transfer
5. 100 Mb network adapter - not necessary but it comes with the system anyway 
   and can be used for private LAN connection with robotic library controller
6. Tape drive adapter (whichever is appropriate (SCSI, Fiber Channel) for 
   mover node

ADDITIONAL STORAGE
-------------------
 Additional storage may be needed for large systems to hold databases, 
system information, log files, etc. It can be any kind of appropriate raid 
arrays.

SYSTEM CONFIGURATION
====================
We recommend to have the following configuration:
For the small system (one robotic library with one or 2 tape drives and few 
thousands tapes).
Minimal configuration:
1.host1:  pnfs server, apache web server, configuration_server, log_server, 
alarm_server, inquisitor, event_relay, ratekeeper, postgres DB server, 
file_clerk, volume_clerk, info_server, accounting_server, drivestat_server
2.host2: media_changer(s), library_manager(s), movers

*** Note that this configuration may have problems as the number of accesses 
and their rates increase. It is always better to run one mover
on a separate host

Recommended configuration:
1. host1 : pnfs server
2. host2 (head node): apache web server, configuration_server, log_server, 
   alarm_server, inquisitor, event_relay, ratekeeper
3. host3: media_changer(s), library_manager(s)
4. host4: postgres DB server, file_clerk, volume_clerk, info_server, 
   accounting_server, drivestat_server
5. host5: backups, plots, migration work, etc.This can be done on one of 
   existing hosts but may interfere with operations.
6. one host per mover.
Configuration recommendations:
Consult the following configuration files:
etc/enstore_configuration_template
etc/minimal_enstore.conf - minimal enstore configuration
etc/stk.conf, etc/sam.conf, etc/cdf.conf - production configurations

Configuration considerations:
Create configuratin file by copying either etc/enstore_configuration_template or
etc/minimal_enstore.conf




